<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="S4M">
  <meta property="og:title" content="S4M"/>
  <meta property="og:description" content="Boosting Semi-Supervised Instance Segmentation with SAM"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="S4M">
  <meta name="twitter:description" content="Towards Open-Vocabulary Semantic Segmentation Without Semantic Labels">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Boosting Semi-Supervised Instance Segmentation with SAM</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">S</a><sup>4</sup>M: Boosting Semi-Supervised Instance Segmentation with SAM</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://github.com/yoon-heez" target="_blank">Heeji Yoon</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=zu-I2fYAAAAJ&hl=en&oi=ao" target="_blank">Heeseong Shin</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="https://github.com/eunbeen-hong" target="_blank">Eunbeen Hong</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://github.com/Eenrue" target="_blank">Hyunwook Choi</a><sup>2</sup>,</span>
                <br>
              <span class="author-block">
                <a> Hansang Cho</a><sup>3</sup>,</span>
              <span class="author-block">
                <a> Daun Chung</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://cvlab.kaist.ac.kr/members/faculty" target="_blank">Seungryong Kim</a><sup>1†</sup>
              </span>                    
                <div>
                </div>


                </div>

                  <div class="is-size-5 publication-authors">
                      <span class="author-block"><sup>1</sup>KAIST, <sup>2</sup>Korea University, <sup>3</sup>Samsung Electro-Mechanics</span>
                      <br>
                      <span class="author-block"><sup>*</sup>Equal Contribution, <sup>†</sup>Corresponding Author</span>
                      <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                    </div>
                    <div>
                    <span class="is-size-5 publication-venue">ArXiv 2025</span>

                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2409.19846.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/cvlab-kaist/PixelCLIP" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2409.19846" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- <img src="static/images/motivation.png" alt="Teaser image" class="teaser-image"> -->
      <h2 class="content has-text-justified">
        <!-- In contrast to existing methods utilizing (a) pixel-level semantic labels or (b) image-level semantic labels, we leverage unlabeled masks as supervision, which can be freely generated from vision foundation models such as SAM and DINO. -->
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Semi-supervised instance segmentation poses challenges due to limited labeled data, causing difficulties in accurately localizing distinct object instances. Current teacher-student frameworks still suffer from performance constraints due to unreliable pseudo-label quality stemming from limited labeled data. While the Segment Anything Model (SAM) offers robust segmentation capabilities at various granularities, directly applying SAM introduces challenges such as class-agnostic predictions and potential over-segmentation. To address these complexities, we carefully integrate SAM into the semi-supervised instance segmentation framework, developing a novel distillation method that effectively captures the precise localization capabilities of SAM without compromising semantic recognition. Furthermore, we incorporate pseudo-label refinement as well as a specialized data augmentation with the refined pseudo-labels, resulting in superior performance. We establish state-of-the-art performance, and provide comprehensive experiments and ablation studies to validate the effectiveness of our proposed approach.          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="hero section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Motivation</h2>
      </div>
    </div>
    
    <!-- 이미지 영역 -->
    <div class="columns is-centered">
      <div class="column is-half">
        <img src="static/images/motivation.png" alt="Motivation image" class="method">
      </div>
    </div>

    <!-- 텍스트 영역 -->
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="content has-text-justified">
          We begin by identifying the limitations of existing semi-supervised approaches through visual inspection of pseudo-labels produced by teacher networks. 
          These pseudo-labels tend to correctly classify object categories but often fail in precise localization, commonly merging multiple instances into a single mask.
          Motivated by this observation, we carefully leverage the Segment Anything Model (SAM), not by naively adopting its outputs, but by selectively identifying what to learn and what not to learn.
          This enables us to effectively address both under- and over-segmentation issues within the semi-supervised instance segmentation framework.
        </h2>
      </div>
    </div>

  </div>
</section>

<section class="hero section is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Overall Framework</h2>
        <div class="hero-body">
          <img src="static/images/main_framework.png" alt="Method image" class="method">
        </div>
        
        <h2 class="content has-text-justified">
          S</a><sup>4</sup>M effectively leverages SAM knowledge through three key approaches. First, we improve the teacher network through structural distillation, which distills SAM's inherent spatial understanding. Then, as the student learns from unlabeled images, we apply pseudo-label refinement based on SAM's strong segmentation capability, and further enhance training with instance-aware augmentation, ARP, which leverages the improved pseudo-labels.
        </h2>
    </div>
  </div>
  <div class="columns is-centered">
    <div class="column is-one-third">
      <div class="image-container">
      <img src="static/images/fig3_v2.png" alt="Image 1" class="method">
      <p class="caption1">Structural Distillation</p>    
      </div>
    </div>
    <div class="column is-one-third">
      <div class="image-container">
      <img src="static/images/pseudolabels.png" alt="Image 2" class="method">
      <p class="caption2">Pseudo-label Refinement</p>
      </div>
    </div>
    <div class="column is-one-third">
      <div class="image-container">
      <img src="static/images/ARP.png" alt="Image 2" class="method">
      <p class="caption">Augmentation with Refined Pseudo-label</p>
      </div>
    </div>
  </div>
</div>
</section>

<section class="hero section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Quantitative Results</h2>

    <div class="columns is-centered">
      <div class="column is-half">
        <div class="image-container">
          <img src="static/images/cityscapes_quan_v2.png" alt="Cityscapes Qualitative" class="method">
          <p class="caption1">Average Precision (AP) on Cityscapes under different label ratios  with state-of-the-art methods.</p>
        </div>
      </div>

      <div class="column is-half">
        <div class="image-container">
          <img src="static/images/coco_quan_v2.png" alt="COCO Qualitative" class="method">
          <p class="caption1">Average Precision (AP) on COCO under different label ratios  with state-of-the-art methods.</p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Qualitative Results</h2>

        <h5 class="title is-5">Cityscapes</h5>
        <div class="content has-text-justified" style="margin-bottom: 1.0em;">
          Qualitative comparison on Cityscapes dataset using 10% labeled data, comparing the baseline semi-supervised method
          GuidedDistillation (Berrada et al. 2024).
        </div>
        <img src="static/images/cityscapes_qual_10.png" alt="cityscapes_qual_10" class="method" style="margin-bottom: 2em;">

        <div class="content has-text-justified" style="margin-bottom: 1.0em;">
          Predictions from the supervised teacher (top) and our semi-supervised student (bottom) across different labeled data settings.
        </div>
        <img src="static/images/supple_city_quals.png" alt="supple_city_quals" class="method" style="margin-bottom: 3em;">

        <h5 class="title is-5">COCO</h5>
        <div class="content has-text-justified" style="margin-bottom: 1.0em;">
          Qualitative comparison on COCO dataset using 2% labeled data, comparing the baseline semi-supervised method
          GuidedDistillation (Berrada et al. 2024).
        </div>
        <img src="static/images/coco_main_qual_final.png" alt="COCO_qual_10" class="method" style="margin-bottom: 2em;">

        <div class="content has-text-justified" style="margin-bottom: 1.0em;">
          Predictions from the supervised teacher (top) and our semi-supervised student (bottom) across different labeled data settings.
        </div>
        <img src="static/images/supple_coco_qual_fin.png" alt="COCO_qual_10" class="method" style="margin-bottom: 3em;">
      </div>
    </div>
  </div>
</section>



  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
